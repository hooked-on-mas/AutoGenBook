{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hooked-on-mas/AutoGenBook/blob/main/AutoGenBookJP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzRAYxwdU8jh"
      },
      "source": [
        "## 仕様の策定\n",
        "\n",
        "以下を入力した後，【すべてのセルを実行（Ctrl + F9）】を押してください．  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "caSeJzWrUqYM"
      },
      "outputs": [],
      "source": [
        "# @markdown ## 必須項目\n",
        "# @markdown ### 教科書の内容\n",
        "book_content = \"殺人、推理小説\" #@param {type:\"string\"}\n",
        "# @markdown ### 大まかなページ数\n",
        "n_pages = 15 # @param {\"type\":\"integer\",\"placeholder\":\"40\"}\n",
        "# @markdown ### 出力形式\n",
        "tex_output = True #@param {type:\"boolean\"}\n",
        "pdf_output = True #@param {type:\"boolean\"}\n",
        "md_output = True #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ## 任意項目\n",
        "# @markdown ### 想定する読者層\n",
        "target_readers = \"東野圭吾風の作成が好きな人\" #@param {type:\"string\"}\n",
        "# @markdown ### 数式の出現度合い\n",
        "equation_frequency_level = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "# @markdown ### その他、内容についての要望\n",
        "additional_requirements = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if book_content == \"\":\n",
        "    print('\\033[31m'+'教科書の内容を指定してください。'+'\\033[0m')\n",
        "if n_pages == 0:\n",
        "    print('\\033[31m'+'ページ数を指定してください．'+'\\033[0m')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spXv6uEbsxis"
      },
      "source": [
        "## プロンプトの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6QvuipAzsz3c"
      },
      "outputs": [],
      "source": [
        "# 共通のプロンプト\n",
        "prompt_common = f\"\"\"\n",
        "以下の内容で本を執筆します．\n",
        "{book_content}\n",
        "本全体のページ数は{n_pages}ページ，1ページあたり40行を想定しています．ですます調で記述してください．\n",
        "\"\"\"\n",
        "if target_readers != \"\":\n",
        "    prompt_common += f\"想定読者としては以下を考えています．\\n {target_readers}\"\n",
        "if additional_requirements != \"\":\n",
        "    prompt_common += f\"また，以下を考慮に入れてください．\\n {additional_requirements}\"\n",
        "\n",
        "# 本・章のタイトルと概要の生成用プロンプト\n",
        "prompt_book_title = prompt_common + \"\"\"\n",
        "以上をもとに，以下のようなjson形式で，本・章のタイトル，本・章の概要を示してください．\n",
        "本の概要には，内容の要約だけではなく，本の主な目的やカバーする内容の範囲と深さなどについても触れてください．5から10文ほどで，詳細にお願いします．\n",
        "また，各章に割くべきページ数を考えてください．ページ数は0.1単位で，0.8ページのように書いてください．\n",
        "それに加え，内容の意味的凝集性から考えて，各章を分節化する必要がありますかどうか（needsSubdivision）を考えてください．trueかfalseで答えてください．\n",
        "推測や未確認の情報は含めないでください．また，タイトルに第何章であるかは書かないでください．\n",
        "節の数は必要に応じて変えてください．\n",
        "```json\n",
        "{{\"title\": \"\",\n",
        "\"summary\": \"\",\n",
        "\"childs\":\n",
        "    [{{\"title\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"n_pages\": ,\n",
        "    \"needsSubdivision\":\n",
        "    }},\n",
        "    {{\"title\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"n_pages\": ,\n",
        "    \"needsSubdivision\":\n",
        "    }},\n",
        "    {{\"title\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"n_pages\": ,\n",
        "    \"needsSubdivision\":\n",
        "    }}]\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# 分節化用プロンプト\n",
        "prompt_section_list_creation = prompt_common + \"\"\"\n",
        "以上の情報から，{book_title}というタイトルで本を作成しようと思います．本の概要を以下に示します．\n",
        "{book_summary}\n",
        "その中の{target}についての部分を{n_pages}ページで作成したいです．1ページあたり40行を想定しています．\n",
        "この部分の概要は，以下です．\n",
        "{section_summary}\n",
        "この部分を分節化して，複数のパートに分けて欲しいです．\n",
        "各パートのタイトルと概要を以下のようなjson形式にて出力してください．また，各パートに割くべきページ数を考えてください．ページ数は0.1単位で，0.8ページのように書いてください．\n",
        "それに加え，内容の意味的凝集性から考えて，各章を分節化する必要がありますかどうか（needsSubdivision）を考えてください．trueかfalseで答えてください．\n",
        "タイトルに第何章・節であるかは書かないでください．\n",
        "```json\n",
        "[{{\"title\": \"\",\n",
        "\"summary\": \"\",\n",
        "\"n_pages\": ,\n",
        "\"needsSubdivision\":\n",
        "}},\n",
        "{{\"title\": \"\",\n",
        "\"summary\": \"\",\n",
        "\"n_pages\": ,\n",
        "\"needsSubdivision\":\n",
        "}}]\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# 本文の内容の生成用プロンプト\n",
        "prompt_content_creation = prompt_common + \"\"\"\n",
        "以上の情報から，{book_title}というタイトルで本を作成しようと思います．本の概要を以下に示します．\n",
        "{book_summary}\n",
        "その中の{target}についての部分を{n_pages}ページで作成したいです．1ページあたり40行を想定しています．\n",
        "この部分の概要は，以下です．\n",
        "{section_summary}\n",
        "その部分の内容を{n_pages}分，つまり{n_pages} × 40行分をLaTeXで出力してください．プリアンブルで必要なライブラリはすべてインポートされています．\n",
        "推測や未確認の情報は含めないでください．見出しは必要なく，本文のみを出力してください．\n",
        "{equation_frequency}\n",
        "数式をネストしないように，すなわち\\[ \\begin{{align*}} \\end{{align*}} \\]ではなく，\\begin{{align*}} \\end{{align*}}とするよう気をつけてください．\n",
        "出力形式は以下のようにお願いします．\n",
        "```tex\n",
        "本文の内容\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV3gAYrto4GT"
      },
      "source": [
        "## パラメータ設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TvppBhFjo3EF"
      },
      "outputs": [],
      "source": [
        "# パラメータ\n",
        "max_depth = 5 # 1なら節のみ，2なら小節まで．．．\n",
        "max_output_pages = 1.5 # LLMの最大出力ページ数\n",
        "\n",
        "book_node_name = \"book\" # ルートノードの名前\n",
        "\n",
        "openai_api_secret_key_name = 'openai_api' # openai_apiをシークレットキーとして登録した時の変数名\n",
        "model_name = \"gpt-4o\" # モデルの名前"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhRrtxVSAxjw"
      },
      "source": [
        "## ライブラリのインストール・インポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q3yeQIS2AxOa",
        "outputId": "deb3553a-3a22-4c7b-fd21-e6dfcaaa9cfc"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y python3-dev graphviz libgraphviz-dev pkg-config\n",
        "!apt-get install -y latexmk\n",
        "!apt-get install -y texlive-lang-japanese\n",
        "!apt-get install -y texlive-latex-extra\n",
        "!apt-get install -y texlive-science\n",
        "%pip install langchain\n",
        "%pip install -qU langchain-openai\n",
        "%pip install pygraphviz\n",
        "%pip install pylatex\n",
        "\n",
        "%pip install langchain-community\n",
        "%pip install langchain-core\n",
        "%pip install python-dotenv\n",
        "%pip install requests\n",
        "%pip install openai\n",
        "\n",
        "import time,os\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import networkx as nx\n",
        "from google.colab import userdata\n",
        "from IPython.display import Markdown\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from typing import List, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "\n",
        "from pylatex import Command, Document, Section, Subsection, Package\n",
        "from pylatex.section import Chapter\n",
        "from pylatex.utils import NoEscape\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5cjjEOefAJR"
      },
      "source": [
        "## グラフの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5x6iAEg2fAR7"
      },
      "outputs": [],
      "source": [
        "book_graph = nx.DiGraph(book_content=book_content, target_readers=target_readers, equation_frequency_level=equation_frequency_level, additional_requirements=additional_requirements)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muWhg5hpTLId"
      },
      "source": [
        "## タイトル・各章の作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7i5EKOOkBVG"
      },
      "source": [
        "### 関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tbrOoC1oj_Ou"
      },
      "outputs": [],
      "source": [
        "def extract_book_and_chapter_contents(markdown_text):\n",
        "    \"\"\"\n",
        "    Markdown形式のテキストから最初に見つかったJSONデータを抽出し、Pythonの辞書型に変換して返す関数。\n",
        "\n",
        "    Args:\n",
        "        markdown_text (str): Markdown形式の文字列。この文字列の中にJSON形式のデータが含まれていると想定される。\n",
        "\n",
        "    Returns:\n",
        "        dict or None: 正しい形式のJSONが見つかれば辞書型で返し、見つからなかった場合やパースに失敗した場合はNoneを返す。\n",
        "    \"\"\"\n",
        "\n",
        "    # MarkdownからJSONの開始点を見つける\n",
        "    start_index = markdown_text.find('{')\n",
        "    if start_index == -1:\n",
        "        return None\n",
        "\n",
        "    # 文字列全体をトラバースし、ネストされた括弧のバランスをチェックする\n",
        "    brace_count = 0\n",
        "    for i in range(start_index, len(markdown_text)):\n",
        "        if markdown_text[i] == '{':\n",
        "            brace_count += 1\n",
        "        elif markdown_text[i] == '}':\n",
        "            brace_count -= 1\n",
        "\n",
        "        # ブレースのバランスが取れたらその時点で抜き出す\n",
        "        if brace_count == 0:\n",
        "            json_string = markdown_text[start_index:i+1]\n",
        "            try:\n",
        "              # JSON形式に変換\n",
        "              json_data = json.loads(json_string)\n",
        "              return json_data\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSONのパースエラー: {e}\")\n",
        "                return None\n",
        "            return\n",
        "\n",
        "    # 閉じ括弧が見つからない場合\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISN0KhB-kAuo"
      },
      "source": [
        "### LLMによる出力"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "2RY4zngngl57"
      },
      "outputs": [],
      "source": [
        "class ChatOpenRouter(ChatOpenAI):\n",
        "    openai_api_base: str\n",
        "    openai_api_key: str\n",
        "    model_name: str\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str,\n",
        "        openai_api_key: Optional[str] = None,\n",
        "        openai_api_base: str = \"https://openrouter.ai/api/v1\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        openai_api_key = openai_api_key or os.getenv(\"OPENROUTER_OPENAI_API_KEY\")\n",
        "        super().__init__(\n",
        "            openai_api_base=openai_api_base,\n",
        "            openai_api_key=openai_api_key,\n",
        "            model_name=model_name,\n",
        "            **kwargs\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptwpNLJNTDuf",
        "outputId": "2e0a65ed-d131-443d-817e-30a78abb9ec2"
      },
      "outputs": [],
      "source": [
        "openai_api_key = userdata.get(\"API_KEY\")\n",
        "model_name = \"qwen/qwen-2.5-7b-instruct\"\n",
        "llm = ChatOpenRouter(\n",
        "    openai_api_key=openai_api_key,\n",
        "    model_name=model_name\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(prompt_book_title)\n",
        "chain = prompt | llm\n",
        "result = chain.invoke({\n",
        "    \"book_content\": book_content,\n",
        "    \"target_readers\": target_readers,\n",
        "    \"n_pages\": n_pages,\n",
        "    \"additional_requirements\": additional_requirements\n",
        "})\n",
        "\n",
        "book_json = extract_book_and_chapter_contents(result.content)\n",
        "if  book_json == None:\n",
        "  print(\"book_jsonの作成に失敗しました。\")\n",
        "  print(\"result.contentのタイプは\",type(result.content),\"長さは\",len(result.content))\n",
        "  print(\"book_jsonのタイプは\",book_json,)\n",
        "  print(\"恐らくllm_modelのコンテキストlength不足または有料モデルを使用しています。あなたの使用したmodelは\",model_name)\n",
        "else:\n",
        "  print(\"合格\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhgOs-a4kJ59"
      },
      "source": [
        "### 結果を本グラフへ格納"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xdrOGJfqBcf-"
      },
      "outputs": [],
      "source": [
        "# 本について\n",
        "book_graph.add_nodes_from([(\n",
        "    book_node_name,\n",
        "    {\"title\": book_json[\"title\"],\n",
        "    \"summary\": book_json[\"summary\"],\n",
        "    \"n_pages\": n_pages,\n",
        "    \"needsSubdivision\": True}\n",
        ")])\n",
        "\n",
        "# 章（部）について\n",
        "book_graph.add_nodes_from([(str(idx+1), child) for idx, child in enumerate(book_json[\"childs\"])])\n",
        "book_graph.add_edges_from([(book_node_name, str(idx+1)) for idx in range(len(book_json[\"childs\"]))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc84vrut-pZ9"
      },
      "source": [
        "## タイトルと構成の確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW4r36Pr-_Po"
      },
      "source": [
        "### タイトルと構成の表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "collapsed": true,
        "id": "vzGKlqImWtl4",
        "outputId": "acb276b0-f1ea-4edd-cab5-0311ba158bdb"
      },
      "outputs": [],
      "source": [
        "book_node = book_graph.nodes[book_node_name]\n",
        "\n",
        "content_md = \"\"\n",
        "content_md += \"\\n ## タイトル：\" + book_node[\"title\"] + \"（ページ数：\" + str(book_node[\"n_pages\"]) + \"）\"\n",
        "content_md += \"\\n \" + book_node[\"summary\"]\n",
        "for idx, child_node_name in enumerate(book_graph.successors(book_node_name)):\n",
        "    child_node = book_graph.nodes[child_node_name]\n",
        "    content_md += \"\\n ### 第\" + str(idx+1) + \"章：\" + child_node[\"title\"] + \"（ページ数：\" + str(child_node[\"n_pages\"]) + \"）\"\n",
        "    content_md += \"\\n\" + child_node[\"summary\"]\n",
        "\n",
        "Markdown(content_md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfXBblAq_mx6"
      },
      "source": [
        "## 本グラフの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaiIwjSjknP5"
      },
      "source": [
        "### 関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KgA7TIry_W2D"
      },
      "outputs": [],
      "source": [
        "def extract_section_list(markdown_text):\n",
        "\n",
        "    pattern = r'```json\\s*(.*?)\\s*```'\n",
        "    match = re.search(pattern, markdown_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        json_string = match.group(1)\n",
        "        data = json.loads(json_string)\n",
        "        return data\n",
        "    else:\n",
        "        print(\"JSONデータが見つかりませんでした。\")\n",
        "        return None\n",
        "\n",
        "def extract_section_content(markdown_text):\n",
        "\n",
        "    pattern = r'```tex\\s*(.*?)\\s*```'\n",
        "    match = re.search(pattern, markdown_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        tex_string = match.group(1)\n",
        "        return tex_string\n",
        "    else:\n",
        "        print(\"TeXデータが見つかりませんでした。\")\n",
        "        return None\n",
        "\n",
        "def get_equation_frequency(equation_frequency_level):\n",
        "    if equation_frequency_level == 1:\n",
        "        return \"数式はほぼ使用せず、すべての概念を平易な言葉で説明してください。数式が絶対に必要な場合のみ、最小限の使用に留めてください。\"\n",
        "    elif equation_frequency_level == 2:\n",
        "        return \"数式は控えめに使用し、主に文章で説明を行ってください。必要な場合のみ簡単な数式を用いてください。\"\n",
        "    elif equation_frequency_level == 3:\n",
        "        return \"数式と文章による説明をバランス良く組み合わせてください。重要な概念は数式で表現し、それ以外は文章で補足してください。\"\n",
        "    elif equation_frequency_level == 4:\n",
        "        return \"数式を積極的に活用し、概念や関係性を正確に表現してください。ただし、重要な説明は文章でも補足してください。\"\n",
        "    elif equation_frequency_level == 5:\n",
        "        return \"数式を最大限に活用してください。可能な限り多くの概念や関係性を数式で表現してください．\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h67SUYLNkfjh"
      },
      "source": [
        "### LLMによる出力とグラフへ結果の格納"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fvZSOTxb4kpT"
      },
      "outputs": [],
      "source": [
        "book_node = book_graph.nodes[book_node_name]\n",
        "next_parent_list = [book_node_name]\n",
        "\n",
        "for depth in range(max_depth):\n",
        "    parent_list = next_parent_list\n",
        "    next_parent_list = []\n",
        "    for parent_node_name in parent_list:\n",
        "        for _, child_node_name in enumerate(book_graph.successors(parent_node_name)):\n",
        "            parant_node = book_graph.nodes[parent_node_name]\n",
        "            child_node = book_graph.nodes[child_node_name]\n",
        "\n",
        "\n",
        "            if (child_node[\"needsSubdivision\"] or child_node[\"n_pages\"] >= max_output_pages) and depth < max_depth-1:\n",
        "\n",
        "                # LLMによる出力\n",
        "                prompt = ChatPromptTemplate.from_template(prompt_section_list_creation)\n",
        "                chain = prompt | llm\n",
        "\n",
        "                result = chain.invoke(\n",
        "                    {\n",
        "                        \"book_title\": book_node[\"title\"],\n",
        "                        \"book_summary\": book_node[\"summary\"],\n",
        "                        \"equation_frequency\": get_equation_frequency(book_graph.graph[\"equation_frequency_level\"]),\n",
        "                        \"target\": child_node[\"title\"],\n",
        "                        \"n_pages\": child_node[\"n_pages\"],\n",
        "                        \"section_summary\": child_node[\"summary\"]\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # 出力を辞書型に変換\n",
        "                section_json = extract_section_list(result.content)\n",
        "\n",
        "                # グラフノードの作成・結果の格納\n",
        "                book_graph.add_nodes_from([(child_node_name + \"-\" + str(idx+1), grandchild) for idx, grandchild in enumerate(section_json)])\n",
        "                book_graph.add_edges_from([(child_node_name, child_node_name + \"-\" + str(idx+1)) for idx in range(len(section_json))])\n",
        "\n",
        "                # 分節化した場合のみ次の親になる\n",
        "                next_parent_list.append(child_node_name)\n",
        "\n",
        "            elif not child_node[\"needsSubdivision\"] or depth == max_depth-1:\n",
        "\n",
        "                # LLMによる出力\n",
        "                prompt = PromptTemplate.from_template(prompt_content_creation)\n",
        "                chain = prompt | llm\n",
        "\n",
        "                result = chain.invoke(\n",
        "                    {\n",
        "                        \"book_title\": book_node[\"title\"],\n",
        "                        \"book_summary\": book_node[\"summary\"],\n",
        "                        \"equation_frequency\": get_equation_frequency(book_graph.graph[\"equation_frequency_level\"]),\n",
        "                        \"target\": child_node[\"title\"],\n",
        "                        \"n_pages\": child_node[\"n_pages\"],\n",
        "                        \"section_summary\": child_node[\"summary\"]\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # 出力をファイルに保存\n",
        "                contents_tex = extract_section_content(result.content)\n",
        "                with open(child_node_name + \"-p.tex\", mode='w', encoding='UTF-8') as f:\n",
        "                    f.write(contents_tex)\n",
        "\n",
        "                # グラフノードの作成・結果の格納\n",
        "                book_graph.add_nodes_from([(child_node_name + \"-p\", {\"content_file_path\": child_node_name + \"-p.tex\"})])\n",
        "                book_graph.add_edges_from([(child_node_name, child_node_name + \"-p\")])\n",
        "\n",
        "            else:\n",
        "                print(\"Error: needsSubdivision attribute is not set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2LSx8U7PgLB"
      },
      "source": [
        "## 本グラフの表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "zslTqJiALTtk",
        "outputId": "58a7ed07-247d-4f71-d6e7-315e13c565ee"
      },
      "outputs": [],
      "source": [
        "pos = graphviz_layout(book_graph, prog=\"dot\")\n",
        "\n",
        "# matplotlib settings\n",
        "fig = plt.figure(figsize=(20, 10), dpi=300)\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "# draw the network\n",
        "nx.draw(book_graph,\n",
        "        ax=ax,\n",
        "        pos=pos,\n",
        "        with_labels=True,\n",
        "        node_size=100,\n",
        "        node_color='w',\n",
        "        alpha=0.4,\n",
        "        node_shape='s',\n",
        "        width=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo3GFevWPjpy"
      },
      "source": [
        "## 本の作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of2bOA5hPs0Q"
      },
      "source": [
        "### latexmkrcファイルの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYXVeE97MhsD",
        "outputId": "424de1d2-a844-4dfe-e62d-9fb5be183f4d"
      },
      "outputs": [],
      "source": [
        "# ホームディレクトリのパスを取得\n",
        "home_dir = os.path.expanduser(\"~\")\n",
        "\n",
        "# .latexmkrcファイルのパスを作成\n",
        "latexmkrc_path = os.path.join(home_dir, \".latexmkrc\")\n",
        "\n",
        "# latexmkrcファイルの中身\n",
        "content = '''$latex = 'platex -synctex=1 -halt-on-error -interaction=nonstopmode -file-line-error %O %S';\n",
        "$bibtex = 'pbibtex %O %S';\n",
        "$biber = 'biber --bblencoding=utf8 -u -U --output_safechars %O %S';\n",
        "$makeindex = 'mendex %O -o %D %S';\n",
        "$dvipdf = 'dvipdfmx %O -o %D %S';\n",
        "\n",
        "$max_repeat = 5;\n",
        "$pdf_mode = 3;'''\n",
        "\n",
        "# ファイルを作成して内容を書き込む\n",
        "try:\n",
        "    with open(latexmkrc_path, \"w\") as file:\n",
        "        file.write(content)\n",
        "    print(f\".latexmkrc file has been created successfully at {latexmkrc_path}\")\n",
        "except IOError as e:\n",
        "    print(f\"An error occurred while creating the file: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJzQSz1qPxtj"
      },
      "source": [
        "### LaTeXで本文の作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnnEFbd6lqLF"
      },
      "source": [
        "### 関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PVixTMSzlvq_"
      },
      "outputs": [],
      "source": [
        "def extract_content_list(string_list):\n",
        "    # この関数は、入力されたstring_listから特定のパターン（数字とハイフンの組み合わせで'-p'で終わる）\n",
        "    # にマッチする文字列のみを抽出し、新しいリストとして返す\n",
        "    pattern = r'(?:\\d+-)*\\d+-p'\n",
        "    return [s for s in string_list if re.match(pattern, s)]\n",
        "\n",
        "def custom_sort_key(s):\n",
        "    # この関数は、文字列sを数字の部分で分割し、それらを整数のリストに変換する\n",
        "    # これにより、数値的な順序でソートするためのカスタムキーを生成する\n",
        "    parts = re.split(r'[-p]', s)\n",
        "    return [int(part) for part in parts if part != '']\n",
        "\n",
        "def sort_strings(string_list):\n",
        "    # この関数は、入力されたstring_listを、custom_sort_key関数で定義された\n",
        "    # カスタムキーを使用してソートし、ソートされた新しいリストを返す\n",
        "    sorted_strings = sorted(string_list, key=custom_sort_key)\n",
        "    return sorted_strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzDdxuC9lwXQ"
      },
      "source": [
        "### LaTeXドキュメントの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RtEA6rVWPv1R"
      },
      "outputs": [],
      "source": [
        "# pylatexにより、PDFを作成\n",
        "geometry_options = {\"tmargin\": \"3cm\", \"lmargin\": \"3cm\"}\n",
        "doc = Document(documentclass=\"jsreport\", geometry_options=geometry_options)\n",
        "\n",
        "# プリアンブル・タイトルの追加\n",
        "doc.packages.append(Package('amsmath'))\n",
        "doc.packages.append(Package('amssymb'))\n",
        "doc.packages.append(Package('amsfonts'))\n",
        "doc.packages.append(Package('mathtools'))\n",
        "doc.packages.append(Package('bm'))\n",
        "doc.packages.append(Package('physics'))\n",
        "doc.packages.append(Package('inputenc', options=\"utf8\"))\n",
        "doc.preamble.append(Command(\"title\", book_graph.nodes[book_node_name][\"title\"]))\n",
        "doc.preamble.append(Command(\"date\", NoEscape(r\"\\today\")))\n",
        "doc.append(NoEscape(r\"\\maketitle\"))\n",
        "doc.append(NoEscape(r\"\\tableofcontents\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yN9GMsGGRX3i"
      },
      "outputs": [],
      "source": [
        "# 本文の内容を持つノードを順番に並び替え\n",
        "content_str_list = extract_content_list(list(book_graph.nodes))\n",
        "sorted_content_str_list = sort_strings(content_str_list)\n",
        "\n",
        "# 本文の追加\n",
        "for heading_number_str in sorted_content_str_list:\n",
        "    heading_number = custom_sort_key(heading_number_str)\n",
        "\n",
        "    # 章の見出しの追加\n",
        "    if len(heading_number[1:]) == 0 or all(x == 1 for x in heading_number[1:]):\n",
        "        node_name = \"-\".join(map(str, heading_number[0:1]))\n",
        "        with doc.create(Chapter(book_graph.nodes[node_name][\"title\"], label=False)):\n",
        "            doc.append(NoEscape(book_graph.nodes[node_name][\"summary\"].replace(\"\\\\\\\\\",\"\\\\\")))\n",
        "\n",
        "    # 節の見出しの追加\n",
        "    if (len(heading_number[2:]) == 0 and len(heading_number[:2]) > 1) or (len(heading_number[2:]) > 0 and all(x == 1 for x in heading_number[2:])):\n",
        "        node_name = \"-\".join(map(str, heading_number[0:2]))\n",
        "        with doc.create(Section(book_graph.nodes[node_name][\"title\"], label=False)):\n",
        "            doc.append(NoEscape(book_graph.nodes[node_name][\"summary\"].replace(\"\\\\\\\\\",\"\\\\\")))\n",
        "\n",
        "    # 小節の見出しの追加\n",
        "    if (len(heading_number[3:]) == 0 and len(heading_number[:3]) > 2) or (len(heading_number[3:]) > 0 and all(x == 1 for x in heading_number[3:])):\n",
        "        node_name = \"-\".join(map(str, heading_number[0:3]))\n",
        "        with doc.create(Subsection(book_graph.nodes[node_name][\"title\"], label=False)):\n",
        "            doc.append(NoEscape(book_graph.nodes[node_name][\"summary\"].replace(\"\\\\\\\\\",\"\\\\\")))\n",
        "\n",
        "    # 本文の追加\n",
        "    tex_file_path = book_graph.nodes[heading_number_str][\"content_file_path\"]\n",
        "    with open(tex_file_path, \"r\", encoding='UTF-8') as file:\n",
        "        tex_content = file.read()\n",
        "        doc.append(NoEscape(tex_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMiaHctXIDOY",
        "outputId": "77aaf8ce-7667-4e1a-9219-73bb700d1d71"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def test_document_structure(doc):\n",
        "    print(\"ドキュメント構造テスト開始\")\n",
        "\n",
        "    # エンコーディングチェック\n",
        "    try:\n",
        "        content = doc.dumps()\n",
        "        content.encode('utf-8')\n",
        "        print(\"エンコーディングチェック: OK (UTF-8)\")\n",
        "    except UnicodeEncodeError:\n",
        "        print(\"エンコーディングチェック: エラー (UTF-8ではありません)\")\n",
        "\n",
        "    # 日本語文字のチェック\n",
        "    if re.search(r'[ぁ-んァ-ン一-龥]', content):\n",
        "        print(\"日本語文字チェック: OK\")\n",
        "    else:\n",
        "        print(\"日本語文字チェック: 警告 (日本語文字が見つかりません)\")\n",
        "\n",
        "    # ドキュメントクラスのチェック\n",
        "    if \"\\\\documentclass\" in content:\n",
        "        print(\"ドキュメントクラスチェック: OK\")\n",
        "    else:\n",
        "        print(\"ドキュメントクラスチェック: エラー (\\\\documentclassが見つかりません)\")\n",
        "\n",
        "    # タイトルと目次のチェック\n",
        "    if \"\\\\maketitle\" in content and \"\\\\tableofcontents\" in content:\n",
        "        print(\"タイトルと目次チェック: OK\")\n",
        "    else:\n",
        "        print(\"タイトルと目次チェック: 警告 (\\\\maketitleまたは\\\\tableofcontentsが見つかりません)\")\n",
        "\n",
        "    print(\"ドキュメント構造テスト終了\")\n",
        "\n",
        "def check_type(doc):\n",
        "  import sys\n",
        "\n",
        "  # docの内容をダンプ\n",
        "  latex_source = doc.dumps()\n",
        "\n",
        "  # エンコーディングの検出\n",
        "  try:\n",
        "      encoding = sys.getdefaultencoding()\n",
        "      latex_source.encode(encoding)\n",
        "      print(f\"ドキュメントは {encoding} でエンコードされています。\")\n",
        "  except UnicodeEncodeError:\n",
        "      print(\"ドキュメントはUTF-8でエンコードされています。\")\n",
        "\n",
        "  # 総文字数\n",
        "  total_chars = len(latex_source)\n",
        "  print(f\"総文字数: {total_chars}\")\n",
        "\n",
        "\n",
        "  # 総バイト数\n",
        "  if encoding == \"utf-8\":\n",
        "    print(f\"総バイト数: {total_chars*3}\")\n",
        "\n",
        "  # ASCII文字とnon-ASCII文字の数をカウント\n",
        "  ascii_chars = sum(1 for c in latex_source if ord(c) < 128)\n",
        "  non_ascii_chars = total_chars - ascii_chars\n",
        "  print(f\"ASCII文字数: {ascii_chars}\")\n",
        "  print(f\"非ASCII文字数: {non_ascii_chars}\")\n",
        "\n",
        "  # BOMの確認\n",
        "  if latex_source.startswith('\\ufeff'):\n",
        "      print(\"BOM (Byte Order Mark) が検出されました。\")\n",
        "  else:\n",
        "      print(\"BOMは検出されませんでした。\")\n",
        "\n",
        "  # LaTeXの入力エンコーディング設定を確認\n",
        "  if r'\\usepackage[utf8]{inputenc}' in latex_source:\n",
        "      print(\"LaTeXはUTF-8入力を使用するように設定されています。\")\n",
        "  elif r'\\usepackage[latin1]{inputenc}' in latex_source:\n",
        "      print(\"LaTeXはLatin-1 (ISO-8859-1) 入力を使用するように設定されています。\")\n",
        "  else:\n",
        "      print(\"LaTeXの入力エンコーディング設定が見つかりません。\")\n",
        "\n",
        "# テストの実行　信用しないで\n",
        "print(type(doc))\n",
        "test_document_structure(doc)\n",
        "print()\n",
        "check_type(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58jBeL42P2SF"
      },
      "source": [
        "### PDF生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "DclfbWmyP2d2",
        "outputId": "c64330c5-4e38-45e9-b071-815b913a8b16"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "!rm -rf /content/*\n",
        "!ls /content\n",
        "doc.generate_tex(filepath=\"doc\")\n",
        "!ls /content\n",
        "\n",
        "print()\n",
        "doc.generate_pdf(\n",
        "    book_node[\"title\"],\n",
        "    clean_tex=False,\n",
        "    silent=False\n",
        ") # コンパイルエラーによりUnicodeDecodeErrorが出る\n",
        "!ls /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRw0GNFES0_H"
      },
      "outputs": [],
      "source": [
        "# ダウンロード\n",
        "if tex_output:\n",
        "    files.download(\"/content/\" + book_node[\"title\"] + \".tex\")\n",
        "\n",
        "if pdf_output:\n",
        "    files.download(\"/content/\" + book_node[\"title\"] + \".pdf\")\n",
        "\n",
        "if md_output:\n",
        "    %pip install latex2markdown\n",
        "    import latex2markdown\n",
        "\n",
        "    with open(\"/content/\" + book_node[\"title\"] + \".tex\", \"r\") as f:\n",
        "        latex_string = f.read()\n",
        "\n",
        "    l2m = latex2markdown.LaTeX2Markdown(latex_string)\n",
        "\n",
        "    markdown_string = l2m.to_markdown()\n",
        "\n",
        "    with open(\"/content/\" + book_node[\"title\"] + \".md\", \"w\") as f:\n",
        "        f.write(markdown_string)\n",
        "    files.download(\"/content/\" + book_node[\"title\"] + \".md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO3zD-07Bn1_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "spXv6uEbsxis",
        "oV3gAYrto4GT",
        "YhRrtxVSAxjw",
        "M5cjjEOefAJR",
        "H7i5EKOOkBVG",
        "ISN0KhB-kAuo",
        "mhgOs-a4kJ59",
        "TaiIwjSjknP5",
        "Of2bOA5hPs0Q",
        "NnnEFbd6lqLF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
