{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hooked-on-mas/AutoGenBook/blob/main/AutoGenBook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzRAYxwdU8jh"
      },
      "source": [
        "## Specification Development\n",
        "\n",
        "After entering the following, please press [Run all cells (Ctrl + F9)]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caSeJzWrUqYM"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Required fields\n",
        "# @markdown ### Textbook content\n",
        "book_content = \"Linear Algebra for Machine Learning\" # @param {type:\"string\"}\n",
        "# @markdown ### Approximate number of pages\n",
        "n_pages = 40 # @param {\"type\":\"integer\",\"placeholder\":\"40\"}\n",
        "\n",
        "# @markdown ## Optional fields\n",
        "# @markdown ### Target audience\n",
        "target_readers = \"Second-year undergraduate students in information science\" # @param {type:\"string\"}\n",
        "# @markdown ### Frequency of equations\n",
        "equation_frequency_level = 4 # @param {type:\"slider\", min:1, max:5, step:1}\n",
        "# @markdown ### Additional requirements regarding content\n",
        "additional_requirements = \"Assuming students have already completed general linear algebra, the course will also serve as a review, focusing in detail on topics commonly used in machine learning.\" # @param {type:\"string\"}\n",
        "\n",
        "if book_content == \"\":\n",
        "    print('\\033[31m'+'Please specify the textbook content.'+'\\033[0m')\n",
        "if n_pages == 0:\n",
        "    print('\\033[31m'+'Please specify the number of pages.'+'\\033[0m')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spXv6uEbsxis"
      },
      "source": [
        "## Definition of Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QvuipAzsz3c"
      },
      "outputs": [],
      "source": [
        "# Common Prompt\n",
        "prompt_common = f\"\"\"\n",
        "We will write a book based on the following content:\n",
        "{book_content}\n",
        "The total number of pages for the entire book is expected to be {n_pages}, with 40 lines per page.\n",
        "\"\"\"\n",
        "if target_readers != \"\":\n",
        "    prompt_common += f\"We are considering the following as the intended audience.\\n {target_readers}\"\n",
        "if additional_requirements != \"\":\n",
        "    prompt_common += f\"Also, please take the following into consideration.\\n {additional_requirements}\"\n",
        "\n",
        "# Prompt for generating book/chapter titles and summaries\n",
        "prompt_book_title = prompt_common + \"\"\"\n",
        "Based on the above, please provide the book and chapter titles and summaries in the following JSON format.\n",
        "For the book's summary, not only include a synopsis but also touch on the book's main objectives, the scope of its contents, and the depth it covers. Write 5 to 10 sentences in detail.\n",
        "Also, consider how many pages should be allocated to each chapter. Write the page number in 0.1 increments, such as 0.8 pages.\n",
        "Additionally, consider whether each chapter needs subdivision based on semantic cohesion (needsSubdivision). Answer with true or false.\n",
        "Do not include the chapter number in the title.\n",
        "The number of sections should be adjusted as necessary.\n",
        "```json\n",
        "{{\"title\": \"\",\n",
        "\"summary\": \"\",\n",
        "\"childs\":\n",
        "    [{{\"title\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"n_pages\": ,\n",
        "    \"needsSubdivision\":\n",
        "    }},\n",
        "    {{\"title\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"n_pages\": ,\n",
        "    \"needsSubdivision\":\n",
        "    }},\n",
        "    {{\"title\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"n_pages\": ,\n",
        "    \"needsSubdivision\":\n",
        "    }}]\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# Prompt for creating section list\n",
        "prompt_section_list_creation = prompt_common + \"\"\"\n",
        "Based on the information above, I am planning to create a book titled {book_title}. The summary of the book is shown below.\n",
        "{book_summary}\n",
        "I would like to create the section on {target} in {n_pages} pages. It is assumed that there are 40 lines per page.\n",
        "The summary of this section is as follows.\n",
        "I would like to subdivide this section into multiple parts.\n",
        "Please output the titles and summaries of each part in the following JSON format. Also, consider how many pages should be allocated to each part. Write the page number in 0.1 increments, such as 0.8 pages.\n",
        "Additionally, consider whether each section needs subdivision based on semantic cohesion (needsSubdivision). Answer with true or false.\n",
        "Do not include the section number in the title.\n",
        "```json\n",
        "[{{\"title\": \"\",\n",
        "\"summary\": \"\",\n",
        "\"n_pages\": ,\n",
        "\"needsSubdivision\":\n",
        "}},\n",
        "{{\"title\": \"\",\n",
        "\"summary\": \"\",\n",
        "\"n_pages\": ,\n",
        "\"needsSubdivision\":\n",
        "}}]\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# Prompt for generating the content of the text\n",
        "prompt_content_creation = prompt_common + \"\"\"\n",
        "Based on the information above, I am planning to create a book titled {book_title}. The summary of the book is shown below.\n",
        "{book_summary}\n",
        "I would like to create the section on {target} in {n_pages} pages. It is assumed that there are 40 lines per page.\n",
        "The summary of this section is as follows.\n",
        "{section_summary}\n",
        "Please output the content of this section in LaTeX format for {n_pages} pages, which equates to {n_pages} Ã— 40 lines. All necessary libraries have already been imported in the preamble.\n",
        "Do not include any assumptions or unverified information. Do not include headers, only the body text.\n",
        "{equation_frequency}\n",
        "Please use the following format for the output:\n",
        "```tex\n",
        "Body text\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV3gAYrto4GT"
      },
      "source": [
        "## Parameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvppBhFjo3EF"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "max_depth = 3  # 1 for sections only, 2 for subsections, and so on...\n",
        "max_output_pages = 1.5 # Maximum Output Pages for LLM\n",
        "\n",
        "book_node_name = \"book\" # Root node's name\n",
        "\n",
        "openai_api_secret_key_name = 'openai_api' # # Variable name when registering openai_api as a secret key\n",
        "model_name = \"gpt-4o\" # Model's name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhRrtxVSAxjw"
      },
      "source": [
        "## Library Installation and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q3yeQIS2AxOa",
        "outputId": "ef9b8698-2067-457f-a34d-a4cf11b2ebb4"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y python3-dev graphviz libgraphviz-dev pkg-config\n",
        "!apt-get install -y latexmk\n",
        "!apt-get install -y texlive-lang-japanese\n",
        "!apt-get install -y texlive-latex-extra\n",
        "%pip install -qU langchain-openai\n",
        "%pip install pygraphviz\n",
        "%pip install pylatex\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import networkx as nx\n",
        "from google.colab import userdata\n",
        "from IPython.display import Markdown\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from typing import List, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "\n",
        "from pylatex import Command, Document, Section, Subsection, Package\n",
        "from pylatex.section import Chapter\n",
        "from pylatex.utils import NoEscape\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5cjjEOefAJR"
      },
      "source": [
        "## Graph Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x6iAEg2fAR7"
      },
      "outputs": [],
      "source": [
        "book_graph = nx.DiGraph(book_content=book_content, target_readers=target_readers, equation_frequency_level=equation_frequency_level, additional_requirements=additional_requirements)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muWhg5hpTLId"
      },
      "source": [
        "## Creation of Title and Chapters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7i5EKOOkBVG"
      },
      "source": [
        "### Function Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbrOoC1oj_Ou"
      },
      "outputs": [],
      "source": [
        "def extract_book_and_chapter_contents(markdown_text):\n",
        "    \"\"\"\n",
        "    A function that extracts the first found JSON data from text in Markdown format and converts it into a Python dictionary.\n",
        "\n",
        "    Args:\n",
        "        markdown_text (str): A string in Markdown format, expected to contain JSON data.\n",
        "\n",
        "    Returns:\n",
        "        dict or None: If a valid JSON is found, it returns a dictionary; if no valid JSON is found or parsing fails, it returns None.\n",
        "    \"\"\"\n",
        "\n",
        "    # Find the starting point of the JSON in the Markdown\n",
        "    start_index = markdown_text.find('{')\n",
        "    if start_index == -1:\n",
        "        return None\n",
        "\n",
        "    # Traverse the entire string and check the balance of nested braces\n",
        "    brace_count = 0\n",
        "    for i in range(start_index, len(markdown_text)):\n",
        "        if markdown_text[i] == '{':\n",
        "            brace_count += 1\n",
        "        elif markdown_text[i] == '}':\n",
        "            brace_count -= 1\n",
        "\n",
        "        # When the braces balance, extract the string at that point\n",
        "        if brace_count == 0:\n",
        "            json_string = markdown_text[start_index:i+1]\n",
        "            try:\n",
        "                # Convert to JSON format\n",
        "                json_data = json.loads(json_string)\n",
        "                return json_data\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing error: {e}\")\n",
        "                return None\n",
        "            return\n",
        "\n",
        "    # If no closing brace is found\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISN0KhB-kAuo"
      },
      "source": [
        "### Output from the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptwpNLJNTDuf"
      },
      "outputs": [],
      "source": [
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(openai_api_secret_key_name)\n",
        "\n",
        "llm = ChatOpenAI(model=model_name)\n",
        "\n",
        "prompt = PromptTemplate.from_template(prompt_book_title)\n",
        "\n",
        "chain = prompt | llm\n",
        "result = chain.invoke(\n",
        "    {\n",
        "        \"book_content\": book_content,\n",
        "        \"target_readers\": target_readers,\n",
        "        \"n_pages\": n_pages,\n",
        "        \"additional_requirements\": additional_requirements\n",
        "    }\n",
        ")\n",
        "\n",
        "book_json = extract_book_and_chapter_contents(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhgOs-a4kJ59"
      },
      "source": [
        "### Result storage in this graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdrOGJfqBcf-"
      },
      "outputs": [],
      "source": [
        "# Regarding the book\n",
        "book_graph.add_nodes_from([(book_node_name, {\"title\": book_json[\"title\"], \"summary\": book_json[\"summary\"], \"n_pages\": n_pages, \"needsSubdivision\": True})])\n",
        "\n",
        "# Regarding chapters (sections)\n",
        "book_graph.add_nodes_from([(str(idx+1), child) for idx, child in enumerate(book_json[\"childs\"])])\n",
        "book_graph.add_edges_from([(book_node_name, str(idx+1)) for idx in range(len(book_json[\"childs\"]))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc84vrut-pZ9"
      },
      "source": [
        "## Title and Content Structure Review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW4r36Pr-_Po"
      },
      "source": [
        "### Title and Structure Display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "collapsed": true,
        "id": "vzGKlqImWtl4",
        "outputId": "fce6eb79-fa98-4eb8-d425-c8d6bf3256a2"
      },
      "outputs": [],
      "source": [
        "book_node = book_graph.nodes[book_node_name]\n",
        "\n",
        "content_md = \"\"\n",
        "content_md += \"\\n ## Title: \" + book_node[\"title\"] + \" (Pages: \" + str(book_node[\"n_pages\"]) + \")\"\n",
        "content_md += \"\\n \" + book_node[\"summary\"]\n",
        "for idx, child_node_name in enumerate(book_graph.successors(book_node_name)):\n",
        "    child_node = book_graph.nodes[child_node_name]\n",
        "    content_md += \"\\n ### Chapter \" + str(idx+1) + \": \" + child_node[\"title\"] + \" (Pages: \" + str(child_node[\"n_pages\"]) + \")\"\n",
        "    content_md += \"\\n\" + child_node[\"summary\"]\n",
        "\n",
        "Markdown(content_md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfXBblAq_mx6"
      },
      "source": [
        "## Creation of the book graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaiIwjSjknP5"
      },
      "source": [
        "### Function Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgA7TIry_W2D"
      },
      "outputs": [],
      "source": [
        "def extract_section_list(markdown_text):\n",
        "\n",
        "    pattern = r'```json\\s*(.*?)\\s*```'\n",
        "    match = re.search(pattern, markdown_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        json_string = match.group(1)\n",
        "        data = json.loads(json_string)\n",
        "        return data\n",
        "    else:\n",
        "        print(\"No JSON data found.\")\n",
        "        return None\n",
        "\n",
        "def extract_section_content(markdown_text):\n",
        "\n",
        "    pattern = r'```tex\\s*(.*?)\\s*```'\n",
        "    match = re.search(pattern, markdown_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        tex_string = match.group(1)\n",
        "        return tex_string\n",
        "    else:\n",
        "        print(\"No TeX data found.\")\n",
        "        return None\n",
        "\n",
        "def get_equation_frequency(equation_frequency_level):\n",
        "    if equation_frequency_level == 1:\n",
        "        return \"Use hardly any equations. Explain all concepts in simple words, and use equations only if absolutely necessary, keeping them to a minimum.\"\n",
        "    elif equation_frequency_level == 2:\n",
        "        return \"Use equations sparingly, explaining primarily in prose. Use simple equations only when needed.\"\n",
        "    elif equation_frequency_level == 3:\n",
        "        return \"Strike a balance between equations and prose. Use equations to express important concepts, with prose providing supplementary explanation.\"\n",
        "    elif equation_frequency_level == 4:\n",
        "        return \"Use equations actively to accurately express concepts and relationships, but still provide key explanations in prose as well.\"\n",
        "    elif equation_frequency_level == 5:\n",
        "        return \"Make full use of equations. Express as many concepts and relationships as possible using equations.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h67SUYLNkfjh"
      },
      "source": [
        "### Output from LLM and storing results in the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAFcBJLtqXkg"
      },
      "outputs": [],
      "source": [
        "book_node = book_graph.nodes[book_node_name]\n",
        "next_parent_list = [book_node_name]\n",
        "\n",
        "for depth in range(max_depth):\n",
        "    parent_list = next_parent_list\n",
        "    next_parent_list = []\n",
        "    for parent_node_name in parent_list:\n",
        "        for _, child_node_name in enumerate(book_graph.successors(parent_node_name)):\n",
        "            parant_node = book_graph.nodes[parent_node_name]\n",
        "            child_node = book_graph.nodes[child_node_name]\n",
        "\n",
        "\n",
        "            if (child_node[\"needsSubdivision\"] or child_node[\"n_pages\"] >= max_output_pages) and depth < max_depth-1:\n",
        "\n",
        "                # Output from the LLM\n",
        "                prompt = PromptTemplate.from_template(prompt_section_list_creation)\n",
        "                chain = prompt | llm\n",
        "\n",
        "                result = chain.invoke(\n",
        "                    {\n",
        "                        \"book_title\": book_node[\"title\"],\n",
        "                        \"book_summary\": book_node[\"summary\"],\n",
        "                        \"equation_frequency\": get_equation_frequency(book_graph.graph[\"equation_frequency_level\"]),\n",
        "                        \"target\": child_node[\"title\"],\n",
        "                        \"n_pages\": child_node[\"n_pages\"],\n",
        "                        \"section_summary\": child_node[\"summary\"]\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # Convert the output to a dictionary\n",
        "                section_json = extract_section_list(result.content)\n",
        "\n",
        "                # Create graph nodes and store the result\n",
        "                book_graph.add_nodes_from([(child_node_name + \"-\" + str(idx+1), grandchild) for idx, grandchild in enumerate(section_json)])\n",
        "                book_graph.add_edges_from([(child_node_name, child_node_name + \"-\" + str(idx+1)) for idx in range(len(section_json))])\n",
        "\n",
        "                # Add to next parent list only if subdivided\n",
        "                next_parent_list.append(child_node_name)\n",
        "\n",
        "            elif not child_node[\"needsSubdivision\"] or depth == max_depth-1:\n",
        "\n",
        "                # Output from the LLM\n",
        "                prompt = PromptTemplate.from_template(prompt_content_creation)\n",
        "                chain = prompt | llm\n",
        "\n",
        "                result = chain.invoke(\n",
        "                    {\n",
        "                        \"book_title\": book_node[\"title\"],\n",
        "                        \"book_summary\": book_node[\"summary\"],\n",
        "                        \"equation_frequency\": get_equation_frequency(book_graph.graph[\"equation_frequency_level\"]),\n",
        "                        \"target\": child_node[\"title\"],\n",
        "                        \"n_pages\": child_node[\"n_pages\"],\n",
        "                        \"section_summary\": child_node[\"summary\"]\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # Save outputs to a file\n",
        "                contents_tex = extract_section_content(result.content)\n",
        "                with open(child_node_name + \"-p.tex\", mode='w', encoding='UTF-8') as f:\n",
        "                    f.write(contents_tex)\n",
        "\n",
        "                # Create graph nodes and store the result\n",
        "                book_graph.add_nodes_from([(child_node_name + \"-p\", {\"content_file_path\": child_node_name + \"-p.tex\"})])\n",
        "                book_graph.add_edges_from([(child_node_name, child_node_name + \"-p\")])\n",
        "\n",
        "            else:\n",
        "                print(\"Error: needsSubdivision attribute is not set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2LSx8U7PgLB"
      },
      "source": [
        "## Book Graph Display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zslTqJiALTtk"
      },
      "outputs": [],
      "source": [
        "pos = graphviz_layout(book_graph, prog=\"dot\")\n",
        "\n",
        "# matplotlib settings\n",
        "fig = plt.figure(figsize=(20, 10), dpi=300)\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "# draw the network\n",
        "nx.draw(book_graph,\n",
        "        ax=ax,\n",
        "        pos=pos,\n",
        "        with_labels=True,\n",
        "        node_size=100,\n",
        "        node_color='w',\n",
        "        alpha=0.4,\n",
        "        node_shape='s',\n",
        "        width=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo3GFevWPjpy"
      },
      "source": [
        "## Book Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnnEFbd6lqLF"
      },
      "source": [
        "### Function Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVixTMSzlvq_"
      },
      "outputs": [],
      "source": [
        "def extract_content_list(string_list):\n",
        "    # This function extracts only the strings from the input string_list\n",
        "    # that match a specific pattern (a combination of numbers and hyphens ending with '-p'),\n",
        "    # and returns them as a new list.\n",
        "    pattern = r'(?:\\d+-)*\\d+-p'\n",
        "    return [s for s in string_list if re.match(pattern, s)]\n",
        "\n",
        "def custom_sort_key(s):\n",
        "    # This function splits the string 's' at the numeric parts,\n",
        "    # converts them into a list of integers, and generates a custom key for sorting\n",
        "    # in numerical order.\n",
        "    parts = re.split(r'[-p]', s)\n",
        "    return [int(part) for part in parts if part != '']\n",
        "\n",
        "def sort_strings(string_list):\n",
        "    # This function sorts the input string_list using the custom key defined\n",
        "    # in the custom_sort_key function and returns the sorted list.\n",
        "    sorted_strings = sorted(string_list, key=custom_sort_key)\n",
        "    return sorted_strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzDdxuC9lwXQ"
      },
      "source": [
        "### LaTeX document Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtEA6rVWPv1R"
      },
      "outputs": [],
      "source": [
        "# Create a LaTeX document with pylatex\n",
        "geometry_options = {\"tmargin\": \"3cm\", \"lmargin\": \"3cm\"}\n",
        "doc = Document(documentclass=\"report\", geometry_options=geometry_options)\n",
        "\n",
        "# Add a preamble and title\n",
        "doc.packages.append(Package('amsmath'))\n",
        "doc.packages.append(Package('amssymb'))\n",
        "doc.packages.append(Package('amsfonts'))\n",
        "doc.packages.append(Package('mathtools'))\n",
        "doc.packages.append(Package('bm'))\n",
        "doc.preamble.append(Command(\"title\", book_graph.nodes[book_node_name][\"title\"]))\n",
        "doc.preamble.append(Command(\"date\", NoEscape(r\"\\today\")))\n",
        "doc.append(NoEscape(r\"\\maketitle\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN9GMsGGRX3i"
      },
      "outputs": [],
      "source": [
        "# Sort nodes containing main content in order\n",
        "content_str_list = extract_content_list(list(book_graph.nodes))\n",
        "sorted_content_str_list = sort_strings(content_str_list)\n",
        "\n",
        "# Add main content\n",
        "for heading_number_str in sorted_content_str_list:\n",
        "    heading_number = custom_sort_key(heading_number_str)\n",
        "\n",
        "    # Add chapter headings\n",
        "    if len(heading_number[1:]) == 0 or all(x == 1 for x in heading_number[1:]):\n",
        "        node_name = \"-\".join(map(str, heading_number[0:1]))\n",
        "        with doc.create(Chapter(book_graph.nodes[node_name][\"title\"])):\n",
        "            doc.append(NoEscape(book_graph.nodes[node_name][\"summary\"].replace(\"\\\\\\\\\",\"\\\\\")))\n",
        "\n",
        "    # Add section headings\n",
        "    if (len(heading_number[2:]) == 0 and len(heading_number[:2]) > 1) or (len(heading_number[2:]) > 0 and all(x == 1 for x in heading_number[2:])):\n",
        "        node_name = \"-\".join(map(str, heading_number[0:2]))\n",
        "        with doc.create(Section(book_graph.nodes[node_name][\"title\"])):\n",
        "            doc.append(NoEscape(book_graph.nodes[node_name][\"summary\"].replace(\"\\\\\\\\\",\"\\\\\")))\n",
        "\n",
        "    # Add subsection headings\n",
        "    if (len(heading_number[3:]) == 0 and len(heading_number[:3]) > 2) or (len(heading_number[3:]) > 0 and all(x == 1 for x in heading_number[3:])):\n",
        "        node_name = \"-\".join(map(str, heading_number[0:3]))\n",
        "        with doc.create(Subsection(book_graph.nodes[node_name][\"title\"])):\n",
        "            doc.append(NoEscape(book_graph.nodes[node_name][\"summary\"].replace(\"\\\\\\\\\",\"\\\\\")))\n",
        "\n",
        "    # Add main text content\n",
        "    tex_file_path = book_graph.nodes[heading_number_str][\"content_file_path\"]\n",
        "    with open(tex_file_path, \"r\", encoding='UTF-8') as file:\n",
        "        tex_content = file.read()\n",
        "        doc.append(NoEscape(tex_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58jBeL42P2SF"
      },
      "source": [
        "### PDF Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DclfbWmyP2d2"
      },
      "outputs": [],
      "source": [
        "# Create a pdf file\n",
        "doc.generate_pdf(book_node[\"title\"], clean_tex=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRw0GNFES0_H"
      },
      "outputs": [],
      "source": [
        "# Download\n",
        "files.download(\"/content/\" + book_node[\"title\"] + \".pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCWAQIh1j1NB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM1DjDLomNlewwhnQ9OgUCb",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
